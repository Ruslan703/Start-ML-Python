{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Pandas\" data-toc-modified-id=\"Pandas-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Pandas</a></span><ul class=\"toc-item\"><li><span><a href=\"#Чтение-файла\" data-toc-modified-id=\"Чтение-файла-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Чтение файла</a></span><ul class=\"toc-item\"><li><span><a href=\"#CSV\" data-toc-modified-id=\"CSV-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>CSV</a></span></li><li><span><a href=\"#Читаем-файл\" data-toc-modified-id=\"Читаем-файл-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Читаем файл</a></span></li><li><span><a href=\"#Беглый-взгляд-на-данные\" data-toc-modified-id=\"Беглый-взгляд-на-данные-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span>Беглый взгляд на данные</a></span></li></ul></li><li><span><a href=\"#Простые-фильтрации\" data-toc-modified-id=\"Простые-фильтрации-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Простые фильтрации</a></span><ul class=\"toc-item\"><li><span><a href=\"#Логическое-&quot;И&quot;\" data-toc-modified-id=\"Логическое-&quot;И&quot;-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Логическое \"И\"</a></span></li><li><span><a href=\"#Логическое-&quot;ИЛИ&quot;\" data-toc-modified-id=\"Логическое-&quot;ИЛИ&quot;-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Логическое \"ИЛИ\"</a></span></li><li><span><a href=\"#Логическое-&quot;НЕ&quot;\" data-toc-modified-id=\"Логическое-&quot;НЕ&quot;-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>Логическое \"НЕ\"</a></span></li></ul></li><li><span><a href=\"#Функции-фильтры\" data-toc-modified-id=\"Функции-фильтры-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Функции-фильтры</a></span><ul class=\"toc-item\"><li><span><a href=\"#.isna()\" data-toc-modified-id=\".isna()-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span><code>.isna()</code></a></span></li><li><span><a href=\"#.isin()\" data-toc-modified-id=\".isin()-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span><code>.isin()</code></a></span></li></ul></li><li><span><a href=\"#Series-и-Index\" data-toc-modified-id=\"Series-и-Index-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Series и Index</a></span></li><li><span><a href=\"#Индекс\" data-toc-modified-id=\"Индекс-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Индекс</a></span><ul class=\"toc-item\"><li><span><a href=\"#Изменение-значения-через-.loc\" data-toc-modified-id=\"Изменение-значения-через-.loc-1.5.1\"><span class=\"toc-item-num\">1.5.1&nbsp;&nbsp;</span>Изменение значения через <code>.loc</code></a></span></li></ul></li><li><span><a href=\"#Группировка\" data-toc-modified-id=\"Группировка-1.6\"><span class=\"toc-item-num\">1.6&nbsp;&nbsp;</span>Группировка</a></span></li><li><span><a href=\"#Время-и-даты\" data-toc-modified-id=\"Время-и-даты-1.7\"><span class=\"toc-item-num\">1.7&nbsp;&nbsp;</span>Время и даты</a></span></li><li><span><a href=\"#Простая-визуализация\" data-toc-modified-id=\"Простая-визуализация-1.8\"><span class=\"toc-item-num\">1.8&nbsp;&nbsp;</span>Простая визуализация</a></span><ul class=\"toc-item\"><li><span><a href=\"#Линии-и-точки-по-данным\" data-toc-modified-id=\"Линии-и-точки-по-данным-1.8.1\"><span class=\"toc-item-num\">1.8.1&nbsp;&nbsp;</span>Линии и точки по данным</a></span></li><li><span><a href=\"#Гистограммы\" data-toc-modified-id=\"Гистограммы-1.8.2\"><span class=\"toc-item-num\">1.8.2&nbsp;&nbsp;</span>Гистограммы</a></span></li><li><span><a href=\"#Точная-настройка-через-matplotlib\" data-toc-modified-id=\"Точная-настройка-через-matplotlib-1.8.3\"><span class=\"toc-item-num\">1.8.3&nbsp;&nbsp;</span>Точная настройка через matplotlib</a></span></li></ul></li><li><span><a href=\"#Сохранение-данных\" data-toc-modified-id=\"Сохранение-данных-1.9\"><span class=\"toc-item-num\">1.9&nbsp;&nbsp;</span>Сохранение данных</a></span><ul class=\"toc-item\"><li><span><a href=\"#CSV\" data-toc-modified-id=\"CSV-1.9.1\"><span class=\"toc-item-num\">1.9.1&nbsp;&nbsp;</span>CSV</a></span></li><li><span><a href=\"#Excel\" data-toc-modified-id=\"Excel-1.9.2\"><span class=\"toc-item-num\">1.9.2&nbsp;&nbsp;</span>Excel</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "Этот урок мы посвятим целиком знакомству с библиотекой `pandas`. \n",
    "\n",
    "Мы научимся читать файлы, фильтровать и аггрегировать данные, получать инсайты о данных и записывать свои находки в файлы. Это самые часто встречающиеся операции в `pandas` на практике."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чтение файла\n",
    "Обычно работа с данными начинается с их чтения :)\n",
    "\n",
    "Pandas умеет читать данные в самых разных формах хранения:\n",
    "1. CSV (comma separated values, простой формат хранения таблиц).\n",
    "2. Excel таблицы.\n",
    "3. Напрямую из баз данных.\n",
    "4. Веб-форматы: `json`, `xml`.\n",
    "5. Специальные форматы для данных: `parquet`, `feather`, `orc`.\n",
    "\n",
    "Мы сегодня научимся читать CSV. Это очень простой формат, и из-за этого такой популярный: почти во всех соревнованиях по data science входные данные дают именно в CSV.\n",
    "\n",
    "Не переживайте, pandas всегда будет приводить все читаемые данные к одному формату - поэтому вы без труда сможете открыть любой другой источник, если будете уметь работать с CSV.\n",
    "\n",
    "### CSV\n",
    "\n",
    "Формат CSV очень простой: на каждую запись выделяется отдельная строка, а колонки отделяются специальным символом (по умолчанию запятой `,`).\n",
    "\n",
    "Так, таблица \n",
    "\n",
    "| Имя  | Возраст | Город    |\n",
    "|------|---------|----------|\n",
    "| Миша | 28      | Москва   |\n",
    "| Саша | 12      | Казань   |\n",
    "| Илья | 54      | Мурманск |\n",
    "\n",
    "будет выглядеть как\n",
    "```csv\n",
    "Имя,Возраст,Город\n",
    "Миша,28,Москва\n",
    "Саша,12,Казань\n",
    "Илья,54,Мурманск\n",
    "```\n",
    "\n",
    "### Читаем файл\n",
    "Мы заранее подготовили файлик CSV с данными.\n",
    "Эти данные взяты из [соревнования на Kaggle](https://www.kaggle.com/c/bike-sharing-demand/data?select=train.csv). Kaggle - это площадка для соревнований в области Data Science, где любой может посоревноваться и выиграть денежную награду.\n",
    "\n",
    "Данные представляют из себя записи об аренде велосипедов в разные дни:\n",
    "1. Дата и время (промежуток 1 час)\n",
    "2. Какое время года\n",
    "3. Погода\n",
    "4. Сколько было аренд среди зарегистрированных пользователей\n",
    "5. Сколько было аренд среди незарегистрированных пользователей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T16:54:55.878769Z",
     "start_time": "2022-01-24T16:54:55.850150Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# CSV файл читается функцией read_csv\n",
    "df = pd.read_csv('train.csv', parse_dates=['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T16:54:57.162684Z",
     "start_time": "2022-01-24T16:54:57.137080Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы только что считали CSV и сохранили как `DataFrame` - тип данных из библиотеки pandas.\n",
    "\n",
    "Давайте посмотрим на то, какие возможности дает `DataFrame`.\n",
    "\n",
    "### Беглый взгляд на данные\n",
    "В `pandas` можно быстро взглянуть на основные характеристики данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T16:34:56.489495Z",
     "start_time": "2022-01-24T16:34:56.469817Z"
    }
   },
   "outputs": [],
   "source": [
    "# Показать первые 5 записей\n",
    "# Можно передать аргумент - столько и покажет\n",
    "# Полезно, чтобы взглянуть на данные\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T16:36:00.155079Z",
     "start_time": "2022-01-24T16:36:00.105520Z"
    }
   },
   "outputs": [],
   "source": [
    "# Подсчитать количество заполненных записей (count),\n",
    "# среднее (mean),\n",
    "# стандартное отклонение (std),\n",
    "# квантили (25%, 50%, 75%),\n",
    "# минимум и максимум (min и max соответственно)\n",
    "# для каждой колонки с числами\n",
    "# Полезно, чтобы посмотреть на масштаб величин и их разброс\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T16:46:40.078143Z",
     "start_time": "2022-01-24T16:46:40.073373Z"
    }
   },
   "outputs": [],
   "source": [
    "# Посмотреть на колонки\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T16:49:33.154051Z",
     "start_time": "2022-01-24T16:49:33.149274Z"
    }
   },
   "outputs": [],
   "source": [
    "df.columns[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T16:50:02.068309Z",
     "start_time": "2022-01-24T16:50:02.061946Z"
    }
   },
   "outputs": [],
   "source": [
    "# И их типы (строки и плохо прочитанные даты помечаются как object)\n",
    "df.dtypes  # d - дата, то есть data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Простые фильтрации\n",
    "В pandas можно быстро и просто фильтровать данные по значениям.\n",
    "Фильров может быть сколько угодно, и они могут быть весьма комплексными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T16:59:52.181130Z",
     "start_time": "2022-01-24T16:59:52.150146Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Можно фильтровать данные через квадратные скобки\n",
    "df[df['workingday'] == 0]  # получить все поездки за выходные\n",
    "\n",
    "# Этот запрос можно читать как \"взять df, где у df поле workingday равно 0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логическое \"И\"\n",
    "Можно потребовать, чтобы выполнилось несколько условий одновременно.\n",
    "Для этого используется оператор `&`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T17:06:58.515808Z",
     "start_time": "2022-01-24T17:06:58.490626Z"
    }
   },
   "outputs": [],
   "source": [
    "# Можно задавать несколько условий\n",
    "# Переносы строк внутри [] не играют роли - мы их делаем только для читаемости\n",
    "df[\n",
    "    (df['workingday'] == 1) & (df['season'] == 1)\n",
    "]\n",
    "\n",
    "# Получим весенние поездки в рабочие дни"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сразу отметим две вещи:\n",
    "1. `&` в pandas означает логическое \"И\" - требование, чтобы оба условия выполнились. Обратите внимание, в питоне есть `and` для логического \"И\" в булевых выраженях. Например, можно написать:\n",
    "```python\n",
    "if var1 is None and len(arr) > 0:\n",
    "     print('var1 is None and array \"arr\" has length > 0')\n",
    "```\n",
    "но в pandas используется **только** `&`. Это из-за того, что выражения `df['workingday'] == 1` не являются булевыми типами (об этом немного позже).\n",
    "2. Оба условия обернуты в скобки. В pandas так стоит делать всегда, так как без них оператор `&` будет выполняться в неправильном порядке и код не запустится.\n",
    "\n",
    "### Логическое \"ИЛИ\"\n",
    "Логическое \"ИЛИ\" делается через символ `|`.\n",
    "Оно требует выполнения хотя бы одного условия из всех.\n",
    "Заметьте, нельзя использовать питоновский `or`, как и в случае с логическим \"И\" (оператор `&`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T17:12:21.257844Z",
     "start_time": "2022-01-24T17:12:21.235225Z"
    }
   },
   "outputs": [],
   "source": [
    "# Либо влажность < 10%, либо температура в Цельсиях строго больше 30\n",
    "df[\n",
    "    (df['humidity'] < 10) | (df['temp'] > 30.)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab2d343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Еще один способ фильтрации\n",
    "df.query(\"season == 1 and temp >= 20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логическое \"НЕ\"\n",
    "Логическое \"НЕ\" делается через символ `~`. Точно так же, как в прошлых операторах, встроенный в Python `not` не подойдет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T17:15:40.815697Z",
     "start_time": "2022-01-24T17:15:40.791933Z"
    }
   },
   "outputs": [],
   "source": [
    "# Не забудьте про скобки, иначе ~ применится в неправильном порядке и получим некорректный результат\n",
    "df[\n",
    "    ~(df['workingday'] == 0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T17:18:48.045160Z",
     "start_time": "2022-01-24T17:18:48.010919Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Когда объединяете \"НЕ\" с другими условиями, окружите его тоже скобками\n",
    "df[\n",
    "    (~(df['workingday'] == 0)) & (df['temp'] >= 10) & (df['temp'] < 30)\n",
    "]\n",
    "# Не рабочий день и температура от 10 включительно до 30 не включительно\n",
    "# можно было использовать df['workingday'] != 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Функции-фильтры\n",
    "В pandas есть много функций для сложных проверок.\n",
    "Пройдемся по главным.\n",
    "### `.isna()`\n",
    "Фильтрует по записям, в которых пропущено значение.\n",
    "Обратите внимание, **нельзя** использовать конструкцию\n",
    "```python\n",
    "df[df['windspeed'] is None]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T17:23:39.730136Z",
     "start_time": "2022-01-24T17:23:39.717140Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# взять df, где у df поле windspeed не заполнено\n",
    "df[df['windspeed'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ничего нет. Это хороший знак - у нас нет пропусков в поле `windspeed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T17:23:50.253919Z",
     "start_time": "2022-01-24T17:23:50.225037Z"
    }
   },
   "outputs": [],
   "source": [
    "# Можно применить функцию над целым DataFrame\n",
    "# True положится в места, где пропущено значение\n",
    "df.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2903498",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fdfb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.notna().all().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bce3990",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.notnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-05T17:01:14.777738Z",
     "start_time": "2021-12-05T17:01:14.773584Z"
    }
   },
   "source": [
    "Судя по всему, у нас вообще все замечательно и пропусков нет нигде.\n",
    "Давайте проверим."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T17:26:23.284197Z",
     "start_time": "2022-01-24T17:26:23.277892Z"
    }
   },
   "outputs": [],
   "source": [
    "df['workingday'].isna().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1935db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['workingday'].isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T17:30:13.998348Z",
     "start_time": "2022-01-24T17:30:13.993173Z"
    }
   },
   "outputs": [],
   "source": [
    "if df.isna().any().any():  # Первый any сворачивает до уровня колонок, второй сворачивает в одно значение\n",
    "    print('если пропуски')\n",
    "else:\n",
    "    print('пропусков нет')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `.isin()`\n",
    "Проверяет, находится ли значение в разрешенном списке.\n",
    "\n",
    "Как и в `.isna()`, мы не можем использовать питоновскую конструкцию `in`:\n",
    "```python\n",
    "df[df['season'] in (1, 2)]\n",
    "```\n",
    "\n",
    "Вместо этого приходится пользоваться `.isin()`. Он работает точно так же."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T17:34:57.052764Z",
     "start_time": "2022-01-24T17:34:57.014654Z"
    }
   },
   "outputs": [],
   "source": [
    "df[df['season'].isin([1, 3, 4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398096d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Product': ['A', 'B', 'C', 'D'],\n",
    "    'Sales': [100, 200, 150, 300],\n",
    "    'Region': ['North', 'South', 'North', 'South']\n",
    "}\n",
    "\n",
    "df_1 = pd.DataFrame(data)\n",
    "print(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8547f18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Такая фильтрация означает, что строка начинается с буквы N\n",
    "df_1[df_1['Region'].str.contains('^N')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56cb933",
   "metadata": {},
   "source": [
    "### `filter` - используется для фильтрации строк или столбцов в DataFrame на основе их имен."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83349bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отбираем те столбцы, которые содержат в своем названии букву s\n",
    "df.filter(like='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707f4fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отбираем те столбцы, которые начинаются на букву s\n",
    "df.filter(regex='^s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2055f057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отбираем те столбцы, которые заканчиваются на букву e\n",
    "df.filter(regex='e$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694780a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Метод filter также может использоваться для фильтрации строк по их индексам.\n",
    "df.filter(items=[1, 3], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eff41ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(items=['datetime', 'temp'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В pandas есть дополнительные функции для работы со строками и датами.\n",
    "Их подробнее рассмотрим в домашней работе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series и Index\n",
    "Примеры выше могли оставить несколько вопросов.\n",
    "1. Почему не работают встроенные `in`, `not`?\n",
    "2. Откуда такой странный синтаксис с квадратными скобками?\n",
    "3. Что будет, если вызвать просто `df['season'] == 1`? Это `True/False` или что-то другое?\n",
    "\n",
    "Давайте начнем с 3-его вопроса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T17:44:28.589617Z",
     "start_time": "2022-01-24T17:44:28.579977Z"
    }
   },
   "outputs": [],
   "source": [
    "df['season'] == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это не `True/False`, а массив из `True/False`!\n",
    "Слева видим числа - это _индекс_ (англ. _index_). Про него расскажем чуть позже.\n",
    "\n",
    "Во всех примерах фильтры на самом деле возвращали объект _Series_.\n",
    "На _Series_ можно смотреть как на DataFrame с одной колонкой.\n",
    "Когда мы вызывали\n",
    "```python\n",
    "df[df['season'] == 1]\n",
    "```\n",
    "мы сначала создавали _Series_ в куске `df['season'] == 1`, затем отдавали в `df[...]`.\n",
    "\"Под капотом\" происходило следующее: pandas искал в Series значения `True`, запоминал их индекс, а затем в оригинальном датафрейме `df` забирал значения по этому индексу.\n",
    "\n",
    "Такое использование _Series_ для логических проверок привело к тому, что встроенные в питон `in` и `not` не работают.\n",
    "Просто запомните, что вместо `df[\"col1\"] in [1, 2, 3]` надо использовать `df[\"col1\"].isin([1, 2, 3])`, а вместо `not` использовать символ `~`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Индекс\n",
    "Индекс в pandas похож на индекс в списках и на ключ в словаре. По элементу индекса можно отбирать элементы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T17:45:28.702044Z",
     "start_time": "2022-01-24T17:45:28.684550Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T17:46:57.371934Z",
     "start_time": "2022-01-24T17:46:57.362658Z"
    }
   },
   "outputs": [],
   "source": [
    "# Для \"прямого\" обращения по индексу используется .loc\n",
    "df.loc[4]  # вернет объект Series с колонками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T17:48:32.672294Z",
     "start_time": "2022-01-24T17:48:32.666450Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[4]['temp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T17:50:06.801930Z",
     "start_time": "2022-01-24T17:50:06.774691Z"
    }
   },
   "outputs": [],
   "source": [
    "# В качестве индекса может быть что угодно\n",
    "# Можно поставить любую колонку в качестве индекса\n",
    "df_dt = df.copy().set_index('datetime')\n",
    "df_dt.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T17:51:34.853857Z",
     "start_time": "2022-01-24T17:51:34.845659Z"
    }
   },
   "outputs": [],
   "source": [
    "df_dt.loc['2011-01-01 01:00:00']  # забираем теперь по-другому"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T17:53:50.343290Z",
     "start_time": "2022-01-24T17:53:50.337781Z"
    }
   },
   "outputs": [],
   "source": [
    "# есть способ забрать по порядку, а не по индексу - .iloc\n",
    "df_dt.iloc[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T17:54:41.337005Z",
     "start_time": "2022-01-24T17:54:41.331988Z"
    }
   },
   "outputs": [],
   "source": [
    "# а еще есть вариант указать сразу и индекс, и колонку - через запятую\n",
    "df_dt.loc['2011-01-01 01:00:00', 'weather']\n",
    "# для .iloc такое не работает, приходится писать через две скобки\n",
    "# df_dt.iloc[4]['weather']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T17:56:16.124612Z",
     "start_time": "2022-01-24T17:56:16.112263Z"
    }
   },
   "outputs": [],
   "source": [
    "# для .loc работает все, что мы знаем из срезов\n",
    "# при указании диапазона берутся все данные, которые лежат между ними\n",
    "# в текущей сортировке\n",
    "df_dt.loc['2011-01-01 01:00:00':'2011-01-01 03:00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf31e2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135659bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# удалить столбец и создать копию датафрейма\n",
    "df.drop(columns='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41922053",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['temp'] > 15, ['season', 'weather']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e042d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1, 0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5120af5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Эти функции возвращают исключительно одно значение на пересечение строки и столбца (в отличие от loc и iloc)\n",
    "df.at[0., 'datetime']\n",
    "df.iat[1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T17:57:59.002565Z",
     "start_time": "2022-01-24T17:57:58.975172Z"
    }
   },
   "outputs": [],
   "source": [
    "# для iloc работает все, что мы знаем из срезов\n",
    "df_dt.iloc[10:20:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Изменение значения через `.loc`\n",
    "`df.loc[...]` позволяет перезаписывать значения - точно по такой же логике, как перезапись значения в словаре по ключу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T17:59:35.858526Z",
     "start_time": "2022-01-24T17:59:35.851351Z"
    }
   },
   "outputs": [],
   "source": [
    "df_dt.loc['2011-01-01 04:00:00', 'weather'] = 234  # элемент с индексом 4\n",
    "df_dt.iloc[4]['weather']  # проверим перезапись"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T18:00:29.618391Z",
     "start_time": "2022-01-24T18:00:29.612968Z"
    }
   },
   "outputs": [],
   "source": [
    "df_dt.iloc[4]['weather'] = -5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T18:00:33.767631Z",
     "start_time": "2022-01-24T18:00:33.760422Z"
    }
   },
   "outputs": [],
   "source": [
    "df_dt.iloc[4]['weather']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T18:05:47.468047Z",
     "start_time": "2022-01-24T18:05:47.438094Z"
    }
   },
   "outputs": [],
   "source": [
    "# индекс можно сбросить на 0, 1, 2\n",
    "df_dt.reset_index()  # возвращает копию, НЕ редактирует исходный датафрейм"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Группировка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хорошо, умеем фильтровать данные.\n",
    "Тем не менее, часто поступают запросы на подсчет какой-то агрегированной величины среди определенной группы данных.\n",
    "\n",
    "Скажем, может поступать запрос \"подсчитай суммарную выручку в разбивке по кварталам\" или \"подсчитай среднее число пользователей за день для каждого дня с начала года\".\n",
    "Особенность таких запросов в том, что их обработка строится в несколько действий:\n",
    "\n",
    "1. Отбираем подмножество по определенному критерию.\n",
    "2. Над подмножеством применяем функцию, которая вернет одно число (т.е. превратит **целое подмножество** в **одно** число).\n",
    "3. Возвращаемся в п.1, отбираем другое подмножество, повторяем алгоритм.\n",
    "4. Возвращаем все полученные агрегации.\n",
    "\n",
    "Такие задачи решаются через **группировку** данных с последующей **агрегацией**.\n",
    "В `pandas` есть все инструменты для решения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T18:13:07.516970Z",
     "start_time": "2022-01-24T18:13:07.500870Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "попросили посчитатать среднюю температуру в разбивке по сезонам.\n",
    "Для этого надо сгруппировать по сезонам, т.е.\n",
    "сделать 4 подмножества данных - по одному на каждый сезон,\n",
    "затем каждую группу \"схлопнуть\" до одного числа - среднего по подмножеству.\n",
    "Получим 4 числа - по одному среднему на каждую группу.\n",
    "\"\"\"\n",
    "# Такой способ рекомендуется использовать\n",
    "df.groupby('season').agg({'temp': 'mean'})\n",
    "# сначала группируем по значению season,\n",
    "# затем просим из каждой группы взять колонку temp и подсчитать mean - среднее\n",
    "# mean - это специальная строка, принимает только определенные значения\n",
    "\n",
    "# доступные функции можно найти здесь\n",
    "# https://stackoverflow.com/questions/53943319/what-are-all-python-pandas-agg-functions?rq=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T18:18:11.518851Z",
     "start_time": "2022-01-24T18:18:11.487979Z"
    }
   },
   "outputs": [],
   "source": [
    "# так мы подсчитаем среднее для всех колонок\n",
    "# аналог можно\n",
    "df_number = df.select_dtypes(include=['int64', 'float64'])\n",
    "# df.select_dtypes(exclude=['object'])\n",
    "df_number.groupby(['season', 'workingday']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T18:20:59.591131Z",
     "start_time": "2022-01-24T18:20:59.577027Z"
    }
   },
   "outputs": [],
   "source": [
    "# а так - только для humidity\n",
    "df.groupby(['season', 'workingday'])['humidity'].mean()\n",
    "# равнозначный код\n",
    "# df.groupby(['season', 'workingday']).agg({'humidity': 'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T18:22:51.408337Z",
     "start_time": "2022-01-24T18:22:51.399066Z"
    }
   },
   "outputs": [],
   "source": [
    "df.groupby(['season', 'workingday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce37006",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(n=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f728f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942c0747",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45894356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отбор 10 наибольших значение по temp\n",
    "df.nlargest(n=10, columns='temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8b6763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отбор 10 наименьших значение по temp\n",
    "df.nsmallest(n=10, columns='temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9166ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['temp'].quantile([0.25, 0.35, 0.45, 0.55, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2287040",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['temp'].var()\n",
    "df['temp'].std()\n",
    "df['temp'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Время и даты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Время и дата в pandas имеют свои особенности, поэтому про них поговорим отдельно.\n",
    "\n",
    "Мы уже знаем `datetime.datetime` и `datetime.date` и использовали их на практике.\n",
    "Но `pandas` имеет свои типы для работы со временем!\n",
    "Это сделано так потому, что библиотека `datetime` не дает той гибкости в работе, которую хотел реализовать pandas.\n",
    "Придется разбираться с этим новым типом. Знакомьтесь, `pd.datetime`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T18:27:36.845223Z",
     "start_time": "2022-01-24T18:27:36.832751Z"
    }
   },
   "outputs": [],
   "source": [
    "# К счастью, любой тип (не только datetime.datetime, но и строки, и числа)\n",
    "# можно преобразовать к pd.datetime\n",
    "pd.to_datetime(df['datetime']) # после преобразования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-06T14:02:54.831539Z",
     "start_time": "2022-01-06T14:02:54.826205Z"
    }
   },
   "outputs": [],
   "source": [
    "# до преобразования\n",
    "df['datetime']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На первый вгляд кажется, что ничего не поменялось. Но посмотрите на тип - без преобразования он был `object`, а с преобразованием стал `datetime64[ns]`. Второй тип более точно умеет работать со временем.\n",
    "\n",
    "Давайте посмотрим, чего же такого хорошего нам дал `pd.datetime`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T18:31:07.662291Z",
     "start_time": "2022-01-24T18:31:07.644177Z"
    }
   },
   "outputs": [],
   "source": [
    "# сохраним результат: создадим копию и в ней превратим колонку в pd.datetime\n",
    "df_1 = df.copy()\n",
    "df_1['datetime'] = pd.to_datetime(df_1['datetime'])\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e944aadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Все строки и только два столбца\n",
    "df_1.loc[:,['datetime', 'season']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4889fd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_1['datetime'].dt.month_name()[0])\n",
    "print(df_1['datetime'].dt.day_name()[0])\n",
    "print(df_1['datetime'].dt.year[0])\n",
    "print(df_1['datetime'].dt.minute[0])\n",
    "print(df_1['datetime'].dt.hour[0])\n",
    "print(df_1['datetime'].dt.weekday[0])\n",
    "print(df_1['datetime'].dt.isocalendar().week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T18:34:49.598006Z",
     "start_time": "2022-01-24T18:34:49.566490Z"
    }
   },
   "outputs": [],
   "source": [
    "# Теперь можно вытягивать куски из даты и использовать в фильтрациях и аггрегациях\n",
    "# Используйте .dt, чтобы вытащить не саму дату, а какую-то ее часть\n",
    "df_1[df_1['datetime'].dt.month == 5]  # через .dt взяли месяц\n",
    "# получили данные за пятый месяц"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В исходном `df` колонка `datetime` считается просто строкой, и `pandas` никак не понимает, что там лежит дата!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T18:36:43.221829Z",
     "start_time": "2022-01-24T18:36:43.217008Z"
    }
   },
   "outputs": [],
   "source": [
    "# выдаст ошибку, т.к. пандас не считал это как дату\n",
    "try:\n",
    "    df[df['datetime'].dt.month == 5]\n",
    "except:\n",
    "    print(\"Не работает\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как можно сделать группировки с использованием `pd.datetime`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T18:37:54.864240Z",
     "start_time": "2022-01-24T18:37:54.844402Z"
    }
   },
   "outputs": [],
   "source": [
    "# Можно использовать .dt.month, чтобы сгруппировать по месяцам\n",
    "df_1.groupby(\n",
    "    df_1['datetime'].dt.month  # для каждого месяца\n",
    ").agg({\n",
    "    'temp': 'mean',  # узнаем среднюю температуру\n",
    "    \"humidity\": 'min'  # и минимальную влажность\n",
    "})  # в разбивке по месяцам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T18:42:40.463097Z",
     "start_time": "2022-01-24T18:42:40.431731Z"
    }
   },
   "outputs": [],
   "source": [
    "# для даты можно узнать день, месяц, день недели, номер недели, год\n",
    "# документация https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#time-date-components\n",
    "rents_by_week = df_1.groupby(\n",
    "    df_1['datetime'].dt.isocalendar().week\n",
    ").agg({\n",
    "    'temp': 'count'\n",
    "})\n",
    "# sample(10) - это взять 10 случайных записей\n",
    "# Чтобы была воспроизводимость, фиксируем random_state\n",
    "rents_by_week.sample(10, random_state=42)\n",
    "# количество поездок в разбивке по неделям"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Простая визуализация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В примере выше мы получили разбивку числа поездок по неделям.\n",
    "Получилась большая таблица, и она весьма трудна для чтения.\n",
    "Давайте ее визуализируем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Линии и точки по данным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T18:46:02.312648Z",
     "start_time": "2022-01-24T18:46:01.406150Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# самые простой способ - попросить pandas нарисовать\n",
    "# но контроля над картинками будет мало\n",
    "rents_by_week.plot(\n",
    "    # названия агрументов приходят из matplotlib.pyplot, см. ниже\n",
    "    xlabel='Номер недели',\n",
    "    ylabel='Число поездок',\n",
    "    title='Количество поездок понедельно',\n",
    "    grid=True,\n",
    "    figsize=(16, 9)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Гистограммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T18:47:54.831973Z",
     "start_time": "2022-01-24T18:47:54.341798Z"
    }
   },
   "outputs": [],
   "source": [
    "# Также в pandas есть встроенная функция для постройки гистограм\n",
    "df_1['temp'].hist(bins=50, figsize=(16, 9))\n",
    "# рисуем распределение температур"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T18:50:33.361375Z",
     "start_time": "2022-01-24T18:50:32.849035Z"
    }
   },
   "outputs": [],
   "source": [
    "ax = rents_by_week.hist(bins=100, figsize=(16, 9))\n",
    "# объект графика возвращается функцией .hist - его можно положить в переменную\n",
    "# затем добавлять все, что хотим. Добавим title\n",
    "# ax[0, 0]: Это выражение извлекает первый (и единственный) элемент из этого массива. \n",
    "# Таким образом, ax теперь ссылается на объект AxesSubplot, который можно использовать для дальнейшей настройки графика.\n",
    "ax[0, 0].set_title('Гистограмма числа поездок понедельно')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что в какие-то недели было очень мало по сравнению с другими.\n",
    "\n",
    "Кажется, что более показательным будет анализ по дням. Давайте сделаем это."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T18:52:30.018966Z",
     "start_time": "2022-01-24T18:52:29.465296Z"
    }
   },
   "outputs": [],
   "source": [
    "ax = df_1.groupby(\n",
    "    df_1['datetime'].dt.dayofyear  # группируем по дням\n",
    ").agg({\n",
    "    'datetime': 'count'  # считаем количество записей в группе\n",
    "}).hist(  # строим гистограмму\n",
    "    bins=100,\n",
    "    figsize=(16, 9)\n",
    ")\n",
    "ax = ax[0, 0]  # matplotlib возвращает двумерный массив, распакуем его\n",
    "ax.set_title('Гистограмма количества поездок ежедневно')\n",
    "ax.set_xlabel('Количество поездок')\n",
    "ax.set_ylabel('Сколько раз было такое количество поездок')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интересный график. Похоже, в большинстве случаев число поездок не сильно разбрасывалось и лежало в диапазоне 45-50, но бывали и дни, когда число поездок падало в два раза.\n",
    "\n",
    "P.S. если явно не указывать левый и правый конец графика, то они подбираются так, чтобы график вместил все данные. То есть, по графику выше можно сделать вывод, что число поездок в день меньше 50 для всех дней."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Точная настройка через matplotlib\n",
    "На самом деле, все функции выше использовали `matplotlib` для визуализации.\n",
    "\n",
    "Мы даже можем самостоятельно отрисовать те же графики через `matplotlib`, что называется, вручную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T18:56:10.971495Z",
     "start_time": "2022-01-24T18:56:10.644919Z"
    }
   },
   "outputs": [],
   "source": [
    "# Через matplrents_by_weekotlib.pyplot можно контролировать все аспекты\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(1, 1, figsize=(16, 9))\n",
    "ax.plot(rents_by_week.index, rents_by_week.temp)\n",
    "# добавим еще точки на тот же график - этого не делали в pandas\n",
    "ax.scatter(\n",
    "    # по оси X - индекс. Наша неделя ушла в индекс после группировки\n",
    "    rents_by_week.index,\n",
    "    # по оси Y - значение колонки 0. Она называется temp, можно было по имени обратиться\n",
    "    rents_by_week.iloc[:, 0]\n",
    ")\n",
    "ax.set_xlabel('Номер недели')\n",
    "ax.set_ylabel('Количество поездок')\n",
    "ax.set_title('Количество поездок понедельно')\n",
    "ax.grid(True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, рисовать через `matplotlib` напрямую не совсем удобно - надо писать много кода и знать названия методов.\n",
    "Рекомендуем пользоваться `df.hist()` и `df.plot()` для рисования графиков, либо же сторонними библиотеками наподобие `seaborn`.\n",
    "\n",
    "К визуализации данных еще вернемся в блоке \"Машинное обучение\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сохранение данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Любой датафрейм из `pandas` можно выгрузить в файл, причем разных форматов.\n",
    "\n",
    "Мы будем учиться выгружать в `CSV` и `Excel`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV\n",
    "Про csv уже говорилось в начале занятия - и в него выгружать очень просто."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T19:00:46.449459Z",
     "start_time": "2022-01-24T19:00:46.442171Z"
    }
   },
   "outputs": [],
   "source": [
    "rents_by_week.to_csv('rents_by_week.csv', sep=';')\n",
    "# sep - это разделитель. По умолчанию запятая,\n",
    "# но \";\" лучше читается, если открывать файл в русском Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T19:00:49.741436Z",
     "start_time": "2022-01-24T19:00:49.726870Z"
    }
   },
   "outputs": [],
   "source": [
    "# если не использовать sep=',', то пандас плохо будет читать\n",
    "pd.read_csv('rents_by_week.csv').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T19:01:25.509489Z",
     "start_time": "2022-01-24T19:01:25.498243Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.read_csv('rents_by_week.csv', sep=';').head(5)  # указываем сепаратор явно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excel\n",
    "Тут немного сложнее.\n",
    "Для записи в Excel есть несколько библиотек, и они **не поставляются** вместе с pandas - надо ставить отдельно.\n",
    "\n",
    "Мы будем использовать `openpyxl`. Установим ее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T19:03:59.327369Z",
     "start_time": "2022-01-24T19:03:58.784039Z"
    }
   },
   "outputs": [],
   "source": [
    "# теперь можем писать в excel\n",
    "# Обратите внимание на engine='openpyxl' - эту бибилотеку только что установили\n",
    "rents_by_week.to_excel('rents_by_week.xlsx', engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-24T19:04:26.568052Z",
     "start_time": "2022-01-24T19:04:26.534093Z"
    }
   },
   "outputs": [],
   "source": [
    "# можно открыть в MS Excel, а можно и в pandas\n",
    "pd.read_excel('rents_by_week.xlsx', engine='openpyxl').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аргумент `engine='openpyxl'` является необязательным.\n",
    "\n",
    "Если его пропустить, то pandas будет пытаться определить самостоятельно движок для обработки файла. На практике это может вылиться в то, что он попросит установить доп. бибилиотеки, поэтому мы советуем явно установить один движок и везде указывать его в pandas. В этом случае вы будете четко контролировать зависимости проекта и четко знать, кого винить в случае проблем с файлами Excel. Более подробно про работу `pd.read_excel` можно прочитать в [документации](https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad69cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "df['month'] = df['date'].dt.month\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f275d1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Product': ['A', 'B', 'C'],\n",
    "    'Jan': [100, 200, 150],\n",
    "    'Feb': [120, 220, 170],\n",
    "    'Mar': [130, 230, 180]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab91753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция melt в Pandas — это мощный инструмент для преобразования DataFrame из широкого формата в длинный.\n",
    "melted_df = df.melt(id_vars='Product', var_name='Month', value_name='Sales')\n",
    "melted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d1fd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Product': ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C'],\n",
    "    'Month': ['Jan', 'Feb', 'Mar', 'Jan', 'Feb', 'Mar', 'Jan', 'Feb', 'Mar'],\n",
    "    'Sales': [100, 120, 130, 200, 220, 230, 150, 170, 180]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa76cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted_df = df.pivot(index='Product', columns='Month', values='Sales')\n",
    "print(pivoted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bee5fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Product': ['A', 'A', 'A', 'B', 'B', 'B', 'C', 'C', 'C'],\n",
    "    'Month': ['Jan', 'Feb', 'Mar', 'Jan', 'Feb', 'Mar', 'Jan', 'Feb', 'Mar'],\n",
    "    'Sales': [100, 120, 130, 200, 220, 230, 150, 170, 180],\n",
    "    'Region': ['North', 'North', 'North', 'South', 'South', 'South', 'East', 'East', 'East']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24b9354",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table_df = df.pivot_table(index='Product', columns='Month', values='Sales', aggfunc='sum')\n",
    "print(pivot_table_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666ef134",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'Product': ['A', 'B', 'C'],\n",
    "    'Jan': [100, 200, 150],\n",
    "    'Feb': [120, 220, 170],\n",
    "    'Mar': [130, 230, 180]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.set_index('Product', inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9d5ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_df = df.stack().reset_index()\n",
    "stacked_df.columns = ['Product', 'Month', 'Sales']\n",
    "stacked_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d982717",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_df['Avg_Sales'] = stacked_df.groupby(\"Product\")[\"Sales\"].transform('mean')\n",
    "stacked_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969ca73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Расширяющееся скользящее среднее\n",
    "stacked_df['Sales'].expanding(min_periods=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1c138a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_df['Sales'].rolling(window=3).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56266c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanding_rolling_mean = df['Sales'].expanding().mean().rolling(window=3).mean()\n",
    "print(expanding_rolling_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81697f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = (\n",
    "    pd.DataFrame(\n",
    "        {\"Product\": [\"B\", \"B\", \"C\"],\n",
    "         \"Sales\": [125, 100, 300]}\n",
    "    )\n",
    ")\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c477bdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[~df.Product.isin(df2.Product.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a5053d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "axis = 0 - значит, что мы будем удалять строки а не столбцы\n",
    "how = any - значит, что если есть несколько пропущенных в строке, то мы удаляем строку\n",
    "thresh = 3 - значит, что в строке должны быть как минимум 3 пропущенных значения\n",
    "inplace=True - удаляй здесь же\n",
    "ignore_index = True - при удалении все равно сохранить индексирование строк\n",
    "subset = ['weather', 'count'] - определение в каких столбцах смотреть на пропущенные значения\n",
    "\"\"\"\n",
    "\n",
    "df.dropna(axis=0, how='any', thresh=3, inplace=False, ignore_index=True, subset=['weather', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d224e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['season', 'holiday', 'weather', 'humidity', 'temp']].min(axis=0) # axis = 1 - найти наименьшее по столбцам\n",
    "df[['season', 'holiday', 'weather', 'humidity', 'temp']].max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc225653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cummulative sum\n",
    "# cummax(), cummin(), cumprod() - произведение\n",
    "df['cum_count'] = df['count'].cumsum()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8fa35f",
   "metadata": {},
   "source": [
    "Функция `rank` в `Pandas` используется для присвоения рангов элементам в `Series` или `DataFrame`. Ранг — это порядковый номер элемента в отсортированном списке. Функция rank предоставляет несколько параметров для настройки способа присвоения рангов, таких как метод разрешения связей, порядок сортировки и т.д. Давайте рассмотрим различные параметры и примеры использования rank.\n",
    "\n",
    "### Основные параметры функции `rank`\n",
    "1. method: Метод разрешения связей (одинаковых значений). Возможные значения:\n",
    "- 'average' (по умолчанию): средний ранг для связанных значений.\n",
    "- 'min': минимальный ранг для связанных значений.\n",
    "- 'max': максимальный ранг для связанных значений.\n",
    "- 'first': ранги присваиваются в порядке появления значений.\n",
    "- 'dense': как 'min', но без пропусков в рангах.\n",
    "2. ascending: Порядок сортировки. Если True (по умолчанию), то сортировка по возрастанию, если False, то по убыванию.\n",
    "3. na_option: Как обрабатывать пропущенные значения. Возможные значения:\n",
    "- 'keep' (по умолчанию): пропущенные значения получают ранг NaN.\n",
    "- 'top': пропущенные значения получают минимальный ранг.\n",
    "- 'bottom': пропущенные значения получают максимальный ранг.\n",
    "4. pct: Если True, то ранги нормализуются в процентном формате."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ae348f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['temp_shift'] = df['temp'].shift(3)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f183dd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rank'] = df['temp'].rank(axis=0, method='dense', numeric_only=True, na_option='bottom', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c920d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.Series([100, 120, 130, 110, 140, 150, 160, 170, 180, 190])\n",
    "print(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867d5aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = sales.rank()\n",
    "print(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e072769",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks_average = sales.rank(method='average')\n",
    "ranks_min = sales.rank(method='min')\n",
    "ranks_max = sales.rank(method='max')\n",
    "ranks_first = sales.rank(method='first')\n",
    "ranks_dense = sales.rank(method='dense')\n",
    "\n",
    "print(\"Average:\", ranks_average)\n",
    "print(\"Min:\", ranks_min)\n",
    "print(\"Max:\", ranks_max)\n",
    "print(\"First:\", ranks_first)\n",
    "print(\"Dense:\", ranks_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea331396",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.Series([100, 120, 130, 110, 140, 150, 160, 170, 180, 190])\n",
    "ranks_descending = sales.rank(ascending=False)\n",
    "print(ranks_descending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a3e90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.Series([100, 120, 130, 110, 140, 150, 160, 170, 180, 190])\n",
    "ranks_pct = sales.rank(pct=True) # Нормализованный ранг (0-1)\n",
    "print(ranks_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fe7992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обрезает все значения снизу и сверху\n",
    "df['temp'].clip(lower=15, upper=25, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67c417a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# С помощью функции assign можно добавить новый столбец или перезаписать старый столбец\n",
    "# df.assign(Sales=df['Sales'] * 0.55)\n",
    "df = \\\n",
    "df.assign(\n",
    "    Total_Revenue=df['Sales'] * 0.55,\n",
    "    Tax=df['Sales'] * 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83c47e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(\n",
    "    Sales_Category=lambda x: x['Sales'].apply(lambda y: 'High' if y > 200 else 'Low')\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcde9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.assign(\n",
    "    Revenue_Difference=lambda x: x['Total_Revenue'] - x['Sales']\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c7354d",
   "metadata": {},
   "source": [
    "Функция `qcut` в Pandas используется для разделения данных на равные интервалы (квантили) на основе значений в столбце. Это особенно полезно, когда вы хотите разделить данные на группы с примерно одинаковым количеством элементов в каждой группе, независимо от диапазона значений.\n",
    "\n",
    "**Основные параметры функции `qcut`**\n",
    "- x: Входной массив данных (Series или список).\n",
    "- q: Количество квантилей или список квантилей.\n",
    "- labels: Метки для каждого интервала (по умолчанию — None).\n",
    "- retbins: Если True, возвращает границы интервалов (по умолчанию — False).\n",
    "- precision: Точность для границ интервалов (по умолчанию — 3).\n",
    "- duplicates: Как обрабатывать дубликаты в данных. Возможные значения: 'raise' (по умолчанию) — вызывать ошибку, 'drop' — удалять дубликаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2d14a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['qcut'] = pd.qcut(df['Sales'], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'], duplicates='drop')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
